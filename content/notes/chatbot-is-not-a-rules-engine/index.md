---
title: "Chatbot 不是把大模型塞进一个老旧的规则引擎里"
date: 2026-01-06T17:17:00+08:00
draft: false
tags: ["随记", "AI", "Chatbot"]
---

很多所谓的「Chatbot」，看起来用了大模型，设计了提示词，准备了知识库和数据集，但它们的底层逻辑其实让人异常熟悉——**熟悉到令人不安**。

它们做的事情是：

> 把知识整理成 *结构化业务规则* ，  
> 再要求大模型 *严格按规则进行分析、判断并生成回复* 。

换句话说，是在用 21 世纪的大模型技术，**复刻上世纪的规则驱动型对话机器人**。

![微软智能助手回形针](windows_paper_clip.webp)

---

## Chatbot 的本质，从来不是“规则执行器”

如果一个 Chatbot 的目标是：

- 按业务流程一步步走
- 在预定义框架里做判断
- 输出完全可解释、可复盘的结果

那么，**其实并不需要大模型**。

[规则引擎](https://en.wikipedia.org/wiki/Drools)、[状态机](https://zh.wikipedia.org/wiki/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA)、[模板系统](https://en.wikipedia.org/wiki/Artificial_Intelligence_Markup_Language)，在确定性问题上反而会**更便宜、更稳定，更可控**。

Chatbot 的核心价值，从来不在于“照着规则走”，而在于**通过概率推理，实现具备泛化能力的智能回答**。

---

## 正确的方向，其实恰恰相反

一个真正合理的 Chatbot 架构，应当是：

- **模型是主脑**
- **数据定义能力边界**
- **系统工程负责稳定性与成本控制**
- **评估与反馈驱动系统持续进化**

它不是先把世界“压扁”成规则，再让模型当一个*高级填空器*。

而是：

> 在足够干净、足够真实的数据分布上，  
> 让模型能力自然生长，  
> 再通过系统工程，把这种能力**稳定地转化、放大，并外溢为业务 KPI**。

---

## 为什么很多团队会“退回规则引擎”

原因其实并不复杂，因为规则引擎：

- 规则 **可解释**
- 流程 **可画图**
- 决策 **可复盘**
- PPT **好汇报**

而模型能力的进化：

- **本质上是概率性的**
- **存在波动与不确定性**
- **可解释性有限**
- **需要长期的系统工程与认知支撑**

在大量团队中，这种回退不仅仅是技术选择的问题，还往往叠加了一个不那么容易被察觉的因素——**互联网产品经理通常不具备完整的 AI 通识认知体系**。

从专家系统 → 机器学习 → 深度学习 → 大语言模型，这一演进过程并非单纯的技术升级，而是**对“智能如何产生”的理解范式发生了转变**。

如果缺失这一认知背景，产品经理对 AI 的理解就很容易停留在一种**更古典的范式**之中：  
认为“智能”应当是规则可枚举、路径可还原、行为可穷举的。

在这样的认知框架下，大模型所体现出的概率推理、不确定性与涌现行为，反而更容易被视为“不可靠”“不可控”“不专业”。

于是，一个看似更稳妥、也更容易被理解和接受的选择就出现了——

> 大模型被“驯化”为了一个看起来很聪明的 **规则驱动型对话机器人**。

---

## Chatbot 的终点，不是“像人”，而是“超级智能”

一个真正成熟的 Chatbot 系统，最终往往会呈现出一种**反直觉**的形态：

- **规则越来越少**
- **数据质量与评估体系越来越重要** 
- **模型升级可以直接映射到业务指标的变化**

当模型能力持续增强时，**业务 KPI 的改善会自然发生**，而不再依赖人工不断补充规则或频繁调整流程。

从本质上看，业务 KPI 的提升来自模型能力与系统工程层面的 scaling——
包括更强的后训练、更高质量的数据工程，以及更大规模的算力投入，而不是人力对规则与流程的线性叠加与修补。

因此，Chatbot 的价值并不在于“模拟人类的思考与对话流程”，  
而在于成为一个由**模型、数据与算力**共同支撑的**超级智能系统**，持续为业务创造增益。

## 延伸阅读
- [《从第一性原理出发，推演一款车主 Chatbot 的实现路径》]({{< ref "notes/first-principles-chatbot-implementation-path/index.md" >}})